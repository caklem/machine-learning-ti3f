{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Praktikum 2**\n",
    "\n",
    "Klasifikasi Berita dengan Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deskripsi**\n",
    "\n",
    "Dalam kasus ini, Anda akan melakukan klasifiaksi berita berdasarkan 3 kategori, yaitu **Sport Hockey**, **Sport Baseball**, dan **Otomotif**. Proses klasifikasi akan menggunakan model Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 1 - Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups # download dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # mengubah koleksi dokumen teks menjadi representasi numerik yang dapat digunakan oleh algoritma pembelajaran mesin\n",
    "from sklearn.linear_model import Perceptron # digunakan untuk pemisahan klasifikasi biner\n",
    "from sklearn.metrics import f1_score, classification_report # f1_score: Ini adalah metrik evaluasi yang digunakan untuk mengukur akurasi model klasifikas, classification_report: Ini adalah fungsi yang digunakan untuk menghasilkan laporan klasifikasi yang merinci berbagai metrik evaluasi, termasuk presisi, recall, f1-score, dan lainnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 2 - Pilih Label dan Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['rec.sport.hockey', 'rec.sport.baseball', 'rec.autos'] # Mengambil 3 katergor\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes')) # digunakan untuk mengunduh dataset 20 newsgroups\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes')) # digunakan untuk mengunduh dataset 20 newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Langkah 3 - Ekstrak Fitur dan Buat Model Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       396\n",
      "           1       0.82      0.83      0.83       397\n",
      "           2       0.88      0.87      0.87       399\n",
      "\n",
      "    accuracy                           0.86      1192\n",
      "   macro avg       0.86      0.86      0.86      1192\n",
      "weighted avg       0.86      0.86      0.86      1192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ekstrak Fitur\n",
    "vectorizer = TfidfVectorizer() # membuat objek TfidfVectorizer\n",
    "\n",
    "# Fit fitur\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data) # Membuat data latih\n",
    "X_test = vectorizer.transform(newsgroups_test.data) # Membuat data uji\n",
    "\n",
    "# Fit Model\n",
    "clf = Perceptron(random_state=11) # Membuat model Perceptron\n",
    "clf.fit(X_train, newsgroups_train.target) # Melatih model\n",
    "\n",
    "# Prediksi\n",
    "predictions = clf.predict(X_test) # Mengambil data prediksi\n",
    "print(classification_report(newsgroups_test.target, predictions)) # Menampilkan laporan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan**\n",
    "\n",
    "Dataset yang digunakan pada kode program diatas adalah 20newsgroup yang terdiri dari sekitar 20.000 dokumen. Scikit-learn bahkan menyediakan fungsi yang memberikan kemudahan untuk mengunduh dan membaca kumpulan dataset dengan menggunakan sklearn.datasets. pada kode program diatas Perceptron mampu melakukan klasifikasi multikelas; strategi yang digunakan adalah one-versus-all untuk melakukan pelatihan untuk setiap kelas dalam data training. Dokumen teks memerlukan ekstraksi fitur salah satunya adalah bobot tf-idf pada kodeprogram diatas digunakan tfidf-vectorizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
